using System.Text.RegularExpressions;
using Core;
using TreeSwapFile;

namespace Services;

public class DatasetService : IDisposable
    {
        private readonly string _swapFilePath;
        private readonly BinaryTreeFileStorage _batchStorage;
        
        // √çndices dos lotes salvos no disco (apenas ponteiros long, baixo consumo)
        private List<long> _trainBatchOffsets;
        private List<long> _validationBatchOffsets;
        
        private int _batchSize;
        private int _contextWindowSize;

        public DatasetService(string swapFilePath)
        {
            _swapFilePath = swapFilePath;
            var batchStoragePath = Path.Combine(Path.GetDirectoryName(swapFilePath) ?? "Dayson", "batches.bts");
            
            // Garante diret√≥rio
            Directory.CreateDirectory(Path.GetDirectoryName(batchStoragePath)!);
            
            _batchStorage = new BinaryTreeFileStorage(batchStoragePath);
            _trainBatchOffsets = new List<long>();
            _validationBatchOffsets = new List<long>();
        }

        /// <summary>
        /// L√™ o dataset do disco (streaming), tokeniza via SQLite e grava lotes bin√°rios.
        /// </summary>
        public void InitializeAndSplit(
            string datasetPath, 
            int contextWindowSize, 
            VocabularyManager vocabManager, // Agora recebe o Manager, n√£o o Dictionary
            string padToken, 
            int batchSize, 
            float validationSplit)
        {
            if (!File.Exists(datasetPath))
                throw new FileNotFoundException("Dataset n√£o encontrado", datasetPath);

            Console.WriteLine($"[DatasetService] Iniciando processamento (Streaming) do dataset...");
            
            _batchStorage.Clear();
            _trainBatchOffsets.Clear();
            _validationBatchOffsets.Clear();
            _batchSize = batchSize;
            _contextWindowSize = contextWindowSize;

            // 1. Tokeniza√ß√£o via Streaming (Memory Efficient)
            // Converte texto -> int[] linha por linha sem carregar o arquivo todo
            var allIndices = new List<int>();
            int padTokenId = vocabManager.GetTokenIndex(padToken);

            using (var reader = new StreamReader(datasetPath))
            {
                string line;
                long lineCount = 0;
                while ((line = reader.ReadLine()) != null)
                {
                    if (string.IsNullOrWhiteSpace(line)) continue;

                    // Regex simples para tokenizar (mesma l√≥gica do VocabularyManager)
                    var tokens = Regex.Split(line.ToLower(), @"(\p{L}+|\p{N}+|[.,!?;:'""/\-])")
                                      .Where(x => !string.IsNullOrWhiteSpace(x));

                    foreach (var token in tokens)
                    {
                        // Busca ID no SQLite (cacheado)
                        int id = vocabManager.GetTokenIndex(token);
                        allIndices.Add(id);
                    }

                    lineCount++;
                    if (lineCount % 10000 == 0) 
                        Console.Write($"\r[DatasetService] Processando linhas: {lineCount:N0}");
                }
            }
            Console.WriteLine($"\n[DatasetService] Total de tokens carregados: {allIndices.Count:N0}");

            // Valida√ß√£o de tamanho m√≠nimo
            int totalSequences = Math.Max(0, allIndices.Count - contextWindowSize);
            if (totalSequences == 0) 
                throw new Exception("Dataset muito pequeno para a janela de contexto.");

            int validationSize = (int)(totalSequences * validationSplit);
            int trainSize = totalSequences - validationSize;

            Console.WriteLine($"[DatasetService] Treino: {trainSize:N0} seqs | Valida√ß√£o: {validationSize:N0} seqs");

            // 2. Gera√ß√£o e Grava√ß√£o dos Lotes
            Console.WriteLine("[DatasetService] Gerando lotes e gravando no disco...");

            // Gera lotes de Treino
            GenerateBatches(allIndices, 0, trainSize, contextWindowSize, batchSize, _trainBatchOffsets);
            
            // Gera lotes de Valida√ß√£o
            GenerateBatches(allIndices, trainSize, totalSequences, contextWindowSize, batchSize, _validationBatchOffsets);

            _batchStorage.Flush();

            // 3. Limpeza Cr√≠tica de Mem√≥ria
            // O array allIndices pode ser grande (ex: 100MB para 25M tokens), 
            // mas agora que salvamos os lotes no disco, n√£o precisamos mais dele.
            allIndices.Clear();
            allIndices.TrimExcess();
            GC.Collect(2, GCCollectionMode.Forced, true);

            Console.WriteLine($"[DatasetService] Processamento conclu√≠do. RAM liberada.");
            Console.WriteLine($"[DatasetService] Lotes Treino: {_trainBatchOffsets.Count} | Lotes Valida√ß√£o: {_validationBatchOffsets.Count}");
        }

        private void GenerateBatches(List<int> data, int startIndex, int count, int contextWindow, int batchSize, List<long> offsetsList)
        {
            var currentBatch = new List<(int[] Input, int[] Target)>(batchSize);
            int seqLen = contextWindow; 

            // Ajuste de seguran√ßa: O √∫ltimo √≠ndice poss√≠vel para come√ßar uma sequ√™ncia √©:
            // (Total de Elementos) - (Tamanho da Sequ√™ncia) - 1 (para o target shiftado)
            // Ex: Se temos 100 itens, seqLen 10.
            // O √∫ltimo input come√ßa em 89 (vai at√© 98), target come√ßa em 90 (vai at√© 99).
            // Se come√ßar em 90, input vai at√© 99, target vai at√© 100 (BOOM).
            
            int maxSafeStartIndex = data.Count - seqLen - 1;

            for (int i = 0; i < count; i++)
            {
                int absoluteIndex = startIndex + i;
                
                // üî• CORRE√á√ÉO BLINDADA: Se ultrapassar o limite seguro, encerra o loop deste lote imediatamente.
                if (absoluteIndex > maxSafeStartIndex)
                {
                    // Console.WriteLine($"[DatasetService] Fim seguro atingido no √≠ndice {absoluteIndex}. Parando gera√ß√£o.");
                    break;
                }
                
                int[] input = new int[seqLen];
                int[] target = new int[seqLen];

                // Copia Input
                data.CopyTo(absoluteIndex, input, 0, seqLen);
                
                // Copia Target (deslocado em 1)
                data.CopyTo(absoluteIndex + 1, target, 0, seqLen);

                currentBatch.Add((input, target));

                if (currentBatch.Count == batchSize)
                {
                    long offset = SaveBatchToDisk(currentBatch);
                    if (offset != -1) offsetsList.Add(offset);
                    currentBatch.Clear();
                }
            }

            // Salva o √∫ltimo lote parcial
            if (currentBatch.Count > 0)
            {
                long offset = SaveBatchToDisk(currentBatch);
                if (offset != -1) offsetsList.Add(offset);
            }
        }

        private long SaveBatchToDisk(List<(int[] Input, int[] Target)> batch)
        {
            try
            {
                using (var ms = new MemoryStream())
                using (var writer = new BinaryWriter(ms))
                {
                    // Formato do Lote em Bytes:
                    // [Int32: Count]
                    // Loop:
                    //   [Int32: SeqLen]
                    //   [Bytes: InputData]
                    //   [Int32: SeqLen]
                    //   [Bytes: TargetData]

                    writer.Write(batch.Count);

                    foreach (var item in batch)
                    {
                        // Inputs
                        writer.Write(item.Input.Length);
                        byte[] inputBytes = new byte[item.Input.Length * sizeof(int)];
                        Buffer.BlockCopy(item.Input, 0, inputBytes, 0, inputBytes.Length);
                        writer.Write(inputBytes);

                        // Targets
                        writer.Write(item.Target.Length);
                        byte[] targetBytes = new byte[item.Target.Length * sizeof(int)];
                        Buffer.BlockCopy(item.Target, 0, targetBytes, 0, targetBytes.Length);
                        writer.Write(targetBytes);
                    }

                    return _batchStorage.StoreData(ms.ToArray());
                }
            }
            catch (Exception ex)
            {
                Console.WriteLine($"[DatasetService] Erro ao salvar lote: {ex.Message}");
                return -1;
            }
        }

        public List<(int[] InputIndices, int[] TargetIndices)>? LoadBatchFromDisk(long offset)
        {
            if (offset < 0) return null;

            try
            {
                byte[] data = _batchStorage.GetDataBytes(offset);
                if (data == null || data.Length == 0) return null;

                var batch = new List<(int[], int[])>();

                using (var ms = new MemoryStream(data))
                using (var reader = new BinaryReader(ms))
                {
                    int count = reader.ReadInt32();

                    for (int i = 0; i < count; i++)
                    {
                        // L√™ Input
                        int inputLen = reader.ReadInt32();
                        byte[] inputBytes = reader.ReadBytes(inputLen * sizeof(int));
                        int[] inputArr = new int[inputLen];
                        Buffer.BlockCopy(inputBytes, 0, inputArr, 0, inputBytes.Length);

                        // L√™ Target
                        int targetLen = reader.ReadInt32();
                        byte[] targetBytes = reader.ReadBytes(targetLen * sizeof(int));
                        int[] targetArr = new int[targetLen];
                        Buffer.BlockCopy(targetBytes, 0, targetArr, 0, targetBytes.Length);

                        batch.Add((inputArr, targetArr));
                    }
                }

                return batch;
            }
            catch (Exception ex)
            {
                Console.WriteLine($"[DatasetService] Falha leitura offset {offset}: {ex.Message}");
                return null;
            }
        }

        public List<long> GetTrainBatchOffsets() => _trainBatchOffsets;
        public List<long> GetValidationBatchOffsets() => _validationBatchOffsets;

        public void Dispose()
        {
            _trainBatchOffsets?.Clear();
            _validationBatchOffsets?.Clear();
            _batchStorage?.Dispose();
            GC.SuppressFinalize(this);
        }
    }